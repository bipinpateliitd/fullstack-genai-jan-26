{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured Output with LangChain and OpenAI\n",
    "\n",
    "## Tutorial Overview\n",
    "\n",
    "This comprehensive tutorial covers **structured output** in LangChain - a powerful feature that allows you to get predictable, validated responses from LLMs in specific formats like JSON objects, Pydantic models, or dataclasses.\n",
    "\n",
    "### What You'll Learn:\n",
    "1. What is structured output and why it matters\n",
    "2. Different schema types (Pydantic, TypedDict, JSON Schema)\n",
    "3. Using `with_structured_output()` method\n",
    "4. Real-world examples and use cases\n",
    "5. Validation and error handling\n",
    "6. Advanced patterns and best practices\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "First, let's install the required packages and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install langchain langchain-openai python-dotenv pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import Optional, List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Verify API key is loaded\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in environment variables\")\n",
    "\n",
    "print(\"‚úÖ Environment setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. What is Structured Output?\n",
    "\n",
    "### The Problem with Unstructured Responses\n",
    "\n",
    "Traditional LLM responses are unstructured text that requires parsing:\n",
    "- **Unpredictable format**: Responses vary in structure\n",
    "- **Difficult to parse**: Requires complex regex or string manipulation\n",
    "- **Error-prone**: Parsing can fail unexpectedly\n",
    "- **No validation**: No guarantee the data is in the expected format\n",
    "\n",
    "### The Solution: Structured Output\n",
    "\n",
    "Structured output allows you to:\n",
    "‚úÖ **Get predictable data formats** (JSON, Pydantic models, dataclasses)\n",
    "‚úÖ **Automatic validation** of response data\n",
    "‚úÖ **Type safety** with Python type hints\n",
    "‚úÖ **Easy integration** with your application logic\n",
    "‚úÖ **Nested structures** for complex data\n",
    "\n",
    "### Key Differences from Tools\n",
    "\n",
    "| Feature | Structured Output | Tools |\n",
    "|---------|------------------|-------|\n",
    "| Response guarantee | Always responds in specified format | May or may not call a tool |\n",
    "| Number of responses | Single response | Can call multiple tools |\n",
    "| Use case | Data extraction, classification | Function execution, actions |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Example: Getting Started\n",
    "\n",
    "Let's start with a simple example to extract person information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ChatOpenAI model\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0  # Lower temperature for more consistent outputs\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Model initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple Pydantic model for person information\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "    name: str = Field(description=\"The person's full name\")\n",
    "    age: int = Field(description=\"The person's age in years\")\n",
    "    email: Optional[str] = Field(default=None, description=\"The person's email address\")\n",
    "\n",
    "# Create a model with structured output\n",
    "structured_llm = llm.with_structured_output(Person)\n",
    "\n",
    "# Test it with a query\n",
    "response = structured_llm.invoke(\"My name is John Doe and I'm 30 years old. My email is john@example.com\")\n",
    "\n",
    "print(\"Response type:\", type(response))\n",
    "print(\"\\nStructured Output:\")\n",
    "print(f\"Name: {response.name}\")\n",
    "print(f\"Age: {response.age}\")\n",
    "print(f\"Email: {response.email}\")\n",
    "print(\"\\nFull object:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Schema Types\n",
    "\n",
    "LangChain supports three main schema types for structured output:\n",
    "\n",
    "### 4.1 Pydantic Models (Recommended)\n",
    "\n",
    "**Advantages:**\n",
    "- Rich feature set with field validation\n",
    "- Detailed field descriptions\n",
    "- Nested structures support\n",
    "- Automatic type conversion\n",
    "- Runtime validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Movie Information Extraction\n",
    "class Actor(BaseModel):\n",
    "    \"\"\"Information about an actor.\"\"\"\n",
    "    name: str = Field(description=\"Actor's full name\")\n",
    "    role: str = Field(description=\"Character name they played\")\n",
    "\n",
    "class MovieDetails(BaseModel):\n",
    "    \"\"\"Detailed information about a movie.\"\"\"\n",
    "    title: str = Field(description=\"Movie title\")\n",
    "    year: int = Field(description=\"Release year\")\n",
    "    cast: List[Actor] = Field(description=\"List of main actors\")\n",
    "    genres: List[str] = Field(description=\"Movie genres\")\n",
    "    budget: Optional[float] = Field(default=None, description=\"Budget in millions USD\")\n",
    "    rating: Optional[float] = Field(default=None, description=\"IMDb rating out of 10\")\n",
    "\n",
    "# Create structured model\n",
    "movie_extractor = llm.with_structured_output(MovieDetails)\n",
    "\n",
    "# Extract movie information\n",
    "movie_info = movie_extractor.invoke(\n",
    "    \"Tell me about The Matrix from 1999. It starred Keanu Reeves as Neo and \"\n",
    "    \"Laurence Fishburne as Morpheus. It's a sci-fi action movie with a budget of 63 million dollars \"\n",
    "    \"and has an IMDb rating of 8.7.\"\n",
    ")\n",
    "\n",
    "print(\"Movie Information Extracted:\")\n",
    "print(f\"Title: {movie_info.title}\")\n",
    "print(f\"Year: {movie_info.year}\")\n",
    "print(f\"Genres: {', '.join(movie_info.genres)}\")\n",
    "print(f\"Budget: ${movie_info.budget}M\")\n",
    "print(f\"Rating: {movie_info.rating}/10\")\n",
    "print(\"\\nCast:\")\n",
    "for actor in movie_info.cast:\n",
    "    print(f\"  - {actor.name} as {actor.role}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 TypedDict (Simpler Alternative)\n",
    "\n",
    "**Use when:**\n",
    "- You don't need runtime validation\n",
    "- You want a lighter-weight solution\n",
    "- Performance is critical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "class ProductInfo(TypedDict):\n",
    "    \"\"\"Product information.\"\"\"\n",
    "    name: str\n",
    "    price: float\n",
    "    category: str\n",
    "    in_stock: bool\n",
    "\n",
    "# Note: TypedDict support may vary by provider\n",
    "# For maximum compatibility, use Pydantic models\n",
    "print(\"TypedDict schema defined (use Pydantic for better support)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 JSON Schema (Maximum Control)\n",
    "\n",
    "**Use when:**\n",
    "- You need maximum control over the schema\n",
    "- You're integrating with external systems\n",
    "- You need cross-language compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON Schema example\n",
    "json_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"sentiment\": {\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"positive\", \"negative\", \"neutral\"],\n",
    "            \"description\": \"The sentiment of the text\"\n",
    "        },\n",
    "        \"confidence\": {\n",
    "            \"type\": \"number\",\n",
    "            \"minimum\": 0,\n",
    "            \"maximum\": 1,\n",
    "            \"description\": \"Confidence score between 0 and 1\"\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"sentiment\", \"confidence\"]\n",
    "}\n",
    "\n",
    "# Note: For JSON Schema, you typically use method=\"json_schema\"\n",
    "print(\"JSON Schema defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Real-World Use Cases\n",
    "\n",
    "### 5.1 Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "class SentimentAnalysis(BaseModel):\n",
    "    \"\"\"Sentiment analysis result.\"\"\"\n",
    "    sentiment: Literal[\"positive\", \"negative\", \"neutral\"] = Field(\n",
    "        description=\"Overall sentiment of the text\"\n",
    "    )\n",
    "    confidence: float = Field(\n",
    "        description=\"Confidence score between 0 and 1\",\n",
    "        ge=0.0,\n",
    "        le=1.0\n",
    "    )\n",
    "    key_phrases: List[str] = Field(\n",
    "        description=\"Key phrases that influenced the sentiment\"\n",
    "    )\n",
    "    emotions: List[str] = Field(\n",
    "        description=\"Detected emotions (e.g., joy, anger, sadness)\"\n",
    "    )\n",
    "\n",
    "# Create sentiment analyzer\n",
    "sentiment_analyzer = llm.with_structured_output(SentimentAnalysis)\n",
    "\n",
    "# Analyze different texts\n",
    "texts = [\n",
    "    \"I absolutely love this product! It exceeded all my expectations and the customer service was amazing!\",\n",
    "    \"This is the worst experience I've ever had. Complete waste of money and time.\",\n",
    "    \"The product is okay. Nothing special, but it does what it's supposed to do.\"\n",
    "]\n",
    "\n",
    "print(\"Sentiment Analysis Results:\\n\")\n",
    "for i, text in enumerate(texts, 1):\n",
    "    result = sentiment_analyzer.invoke(f\"Analyze the sentiment: {text}\")\n",
    "    print(f\"Text {i}: {text[:50]}...\")\n",
    "    print(f\"  Sentiment: {result.sentiment.upper()}\")\n",
    "    print(f\"  Confidence: {result.confidence:.2%}\")\n",
    "    print(f\"  Emotions: {', '.join(result.emotions)}\")\n",
    "    print(f\"  Key Phrases: {', '.join(result.key_phrases)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Data Extraction from Unstructured Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContactInformation(BaseModel):\n",
    "    \"\"\"Contact information extracted from text.\"\"\"\n",
    "    full_name: str = Field(description=\"Person's full name\")\n",
    "    phone: Optional[str] = Field(default=None, description=\"Phone number\")\n",
    "    email: Optional[str] = Field(default=None, description=\"Email address\")\n",
    "    company: Optional[str] = Field(default=None, description=\"Company name\")\n",
    "    job_title: Optional[str] = Field(default=None, description=\"Job title\")\n",
    "    address: Optional[str] = Field(default=None, description=\"Physical address\")\n",
    "\n",
    "# Create contact extractor\n",
    "contact_extractor = llm.with_structured_output(ContactInformation)\n",
    "\n",
    "# Extract from business card text\n",
    "business_card = \"\"\"\n",
    "Dr. Sarah Johnson\n",
    "Chief Technology Officer\n",
    "TechCorp Solutions Inc.\n",
    "Email: sarah.johnson@techcorp.com\n",
    "Phone: +1 (555) 123-4567\n",
    "123 Innovation Drive, Silicon Valley, CA 94025\n",
    "\"\"\"\n",
    "\n",
    "contact = contact_extractor.invoke(f\"Extract contact information from: {business_card}\")\n",
    "\n",
    "print(\"Extracted Contact Information:\")\n",
    "print(f\"Name: {contact.full_name}\")\n",
    "print(f\"Title: {contact.job_title}\")\n",
    "print(f\"Company: {contact.company}\")\n",
    "print(f\"Email: {contact.email}\")\n",
    "print(f\"Phone: {contact.phone}\")\n",
    "print(f\"Address: {contact.address}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Content Classification and Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticleClassification(BaseModel):\n",
    "    \"\"\"Article classification and metadata.\"\"\"\n",
    "    title: str = Field(description=\"Suggested article title\")\n",
    "    category: Literal[\"Technology\", \"Business\", \"Science\", \"Health\", \"Entertainment\", \"Sports\", \"Politics\"] = Field(\n",
    "        description=\"Primary category\"\n",
    "    )\n",
    "    tags: List[str] = Field(description=\"Relevant tags (3-5 tags)\")\n",
    "    summary: str = Field(description=\"Brief summary in 1-2 sentences\")\n",
    "    reading_time_minutes: int = Field(description=\"Estimated reading time in minutes\")\n",
    "    target_audience: str = Field(description=\"Target audience description\")\n",
    "\n",
    "# Create article classifier\n",
    "article_classifier = llm.with_structured_output(ArticleClassification)\n",
    "\n",
    "# Classify an article\n",
    "article_text = \"\"\"\n",
    "Artificial Intelligence is revolutionizing healthcare by enabling early disease detection, \n",
    "personalized treatment plans, and drug discovery. Machine learning algorithms can now analyze \n",
    "medical images with accuracy comparable to expert radiologists. Recent studies show that AI-powered \n",
    "diagnostic tools have reduced diagnosis time by 40% while improving accuracy. Major hospitals are \n",
    "implementing AI systems to predict patient deterioration and optimize resource allocation. However, \n",
    "challenges remain in data privacy, algorithmic bias, and regulatory approval.\n",
    "\"\"\"\n",
    "\n",
    "classification = article_classifier.invoke(f\"Classify this article: {article_text}\")\n",
    "\n",
    "print(\"Article Classification:\")\n",
    "print(f\"Title: {classification.title}\")\n",
    "print(f\"Category: {classification.category}\")\n",
    "print(f\"Tags: {', '.join(classification.tags)}\")\n",
    "print(f\"Summary: {classification.summary}\")\n",
    "print(f\"Reading Time: {classification.reading_time_minutes} minutes\")\n",
    "print(f\"Target Audience: {classification.target_audience}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 E-commerce Product Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductReview(BaseModel):\n",
    "    \"\"\"Structured product review analysis.\"\"\"\n",
    "    overall_rating: int = Field(description=\"Overall rating from 1-5 stars\", ge=1, le=5)\n",
    "    pros: List[str] = Field(description=\"Positive aspects mentioned\")\n",
    "    cons: List[str] = Field(description=\"Negative aspects mentioned\")\n",
    "    would_recommend: bool = Field(description=\"Whether the reviewer would recommend the product\")\n",
    "    quality_score: int = Field(description=\"Product quality score 1-10\", ge=1, le=10)\n",
    "    value_for_money: int = Field(description=\"Value for money score 1-10\", ge=1, le=10)\n",
    "    key_features: List[str] = Field(description=\"Key features highlighted\")\n",
    "\n",
    "# Create review analyzer\n",
    "review_analyzer = llm.with_structured_output(ProductReview)\n",
    "\n",
    "# Analyze a product review\n",
    "review_text = \"\"\"\n",
    "I've been using this laptop for 3 months now and I'm really impressed! The battery life is \n",
    "exceptional - easily lasts 12 hours on a single charge. The display is crisp and vibrant, \n",
    "perfect for photo editing. The build quality feels premium with the aluminum chassis. \n",
    "However, it does get a bit warm during intensive tasks, and the price is quite steep. \n",
    "The keyboard is comfortable for long typing sessions. Overall, despite the high price, \n",
    "I would definitely recommend this to professionals who need reliability and performance.\n",
    "\"\"\"\n",
    "\n",
    "review_analysis = review_analyzer.invoke(f\"Analyze this product review: {review_text}\")\n",
    "\n",
    "print(\"Product Review Analysis:\")\n",
    "print(f\"Overall Rating: {'‚≠ê' * review_analysis.overall_rating}\")\n",
    "print(f\"Quality Score: {review_analysis.quality_score}/10\")\n",
    "print(f\"Value for Money: {review_analysis.value_for_money}/10\")\n",
    "print(f\"Would Recommend: {'Yes ‚úÖ' if review_analysis.would_recommend else 'No ‚ùå'}\")\n",
    "print(\"\\nPros:\")\n",
    "for pro in review_analysis.pros:\n",
    "    print(f\"  ‚úì {pro}\")\n",
    "print(\"\\nCons:\")\n",
    "for con in review_analysis.cons:\n",
    "    print(f\"  ‚úó {con}\")\n",
    "print(\"\\nKey Features:\")\n",
    "for feature in review_analysis.key_features:\n",
    "    print(f\"  ‚Ä¢ {feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Resume/CV Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Education(BaseModel):\n",
    "    \"\"\"Education details.\"\"\"\n",
    "    degree: str = Field(description=\"Degree name\")\n",
    "    institution: str = Field(description=\"Educational institution\")\n",
    "    year: Optional[int] = Field(default=None, description=\"Graduation year\")\n",
    "    field: Optional[str] = Field(default=None, description=\"Field of study\")\n",
    "\n",
    "class WorkExperience(BaseModel):\n",
    "    \"\"\"Work experience details.\"\"\"\n",
    "    job_title: str = Field(description=\"Job title\")\n",
    "    company: str = Field(description=\"Company name\")\n",
    "    duration: str = Field(description=\"Duration of employment\")\n",
    "    responsibilities: List[str] = Field(description=\"Key responsibilities\")\n",
    "\n",
    "class ResumeData(BaseModel):\n",
    "    \"\"\"Structured resume data.\"\"\"\n",
    "    name: str = Field(description=\"Candidate's full name\")\n",
    "    email: Optional[str] = Field(default=None, description=\"Email address\")\n",
    "    phone: Optional[str] = Field(default=None, description=\"Phone number\")\n",
    "    skills: List[str] = Field(description=\"Technical and soft skills\")\n",
    "    education: List[Education] = Field(description=\"Educational background\")\n",
    "    experience: List[WorkExperience] = Field(description=\"Work experience\")\n",
    "    summary: str = Field(description=\"Professional summary\")\n",
    "\n",
    "# Create resume parser\n",
    "resume_parser = llm.with_structured_output(ResumeData)\n",
    "\n",
    "# Parse a resume\n",
    "resume_text = \"\"\"\n",
    "ALEX MARTINEZ\n",
    "Email: alex.martinez@email.com | Phone: (555) 987-6543\n",
    "\n",
    "PROFESSIONAL SUMMARY\n",
    "Senior Software Engineer with 8+ years of experience in full-stack development, \n",
    "specializing in cloud-native applications and microservices architecture.\n",
    "\n",
    "SKILLS\n",
    "Python, JavaScript, React, Node.js, AWS, Docker, Kubernetes, PostgreSQL, MongoDB, CI/CD\n",
    "\n",
    "EXPERIENCE\n",
    "Senior Software Engineer - CloudTech Inc. (2020-Present)\n",
    "- Led development of microservices architecture serving 1M+ users\n",
    "- Implemented CI/CD pipelines reducing deployment time by 60%\n",
    "- Mentored team of 5 junior developers\n",
    "\n",
    "Software Engineer - StartupXYZ (2016-2020)\n",
    "- Built RESTful APIs using Node.js and Express\n",
    "- Developed responsive web applications with React\n",
    "- Optimized database queries improving performance by 40%\n",
    "\n",
    "EDUCATION\n",
    "Bachelor of Science in Computer Science - Tech University (2016)\n",
    "Master of Science in Software Engineering - Innovation Institute (2018)\n",
    "\"\"\"\n",
    "\n",
    "resume_data = resume_parser.invoke(f\"Parse this resume: {resume_text}\")\n",
    "\n",
    "print(\"Parsed Resume Data:\")\n",
    "print(f\"\\nName: {resume_data.name}\")\n",
    "print(f\"Email: {resume_data.email}\")\n",
    "print(f\"Phone: {resume_data.phone}\")\n",
    "print(f\"\\nSummary: {resume_data.summary}\")\n",
    "print(f\"\\nSkills: {', '.join(resume_data.skills)}\")\n",
    "print(\"\\nEducation:\")\n",
    "for edu in resume_data.education:\n",
    "    print(f\"  ‚Ä¢ {edu.degree} in {edu.field} - {edu.institution} ({edu.year})\")\n",
    "print(\"\\nExperience:\")\n",
    "for exp in resume_data.experience:\n",
    "    print(f\"  ‚Ä¢ {exp.job_title} at {exp.company} ({exp.duration})\")\n",
    "    for resp in exp.responsibilities:\n",
    "        print(f\"    - {resp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Advanced Features\n",
    "\n",
    "### 6.1 Including Raw Response\n",
    "\n",
    "Sometimes you need both the structured output AND the raw AI message (for metadata like token counts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleQuery(BaseModel):\n",
    "    \"\"\"A simple query response.\"\"\"\n",
    "    answer: str = Field(description=\"The answer to the question\")\n",
    "    confidence: float = Field(description=\"Confidence level 0-1\")\n",
    "\n",
    "# Create model with include_raw=True\n",
    "model_with_raw = llm.with_structured_output(SimpleQuery, include_raw=True)\n",
    "\n",
    "# Invoke and get both structured output and raw message\n",
    "result = model_with_raw.invoke(\"What is the capital of France?\")\n",
    "\n",
    "print(\"Structured Output:\")\n",
    "print(f\"  Answer: {result['parsed'].answer}\")\n",
    "print(f\"  Confidence: {result['parsed'].confidence}\")\n",
    "print(\"\\nRaw Message Metadata:\")\n",
    "print(f\"  Type: {type(result['raw'])}\")\n",
    "print(f\"  Content: {result['raw'].content[:100]}...\")\n",
    "if hasattr(result['raw'], 'usage_metadata'):\n",
    "    print(f\"  Usage: {result['raw'].usage_metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Different Methods for Structured Output\n",
    "\n",
    "OpenAI and other providers support different methods:\n",
    "- `json_schema`: Uses dedicated structured output features (recommended)\n",
    "- `function_calling`: Derives structured output via tool calls\n",
    "- `json_mode`: Generates valid JSON (schema must be in prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskPriority(BaseModel):\n",
    "    \"\"\"Task priority classification.\"\"\"\n",
    "    task: str = Field(description=\"The task description\")\n",
    "    priority: Literal[\"high\", \"medium\", \"low\"] = Field(description=\"Priority level\")\n",
    "    urgency: bool = Field(description=\"Whether the task is urgent\")\n",
    "\n",
    "# Using json_schema method (strict mode)\n",
    "strict_model = llm.with_structured_output(\n",
    "    TaskPriority,\n",
    "    method=\"json_schema\",\n",
    "    strict=True  # Enforces strict schema adherence\n",
    ")\n",
    "\n",
    "task_result = strict_model.invoke(\n",
    "    \"I need to finish the quarterly report by tomorrow morning for the board meeting.\"\n",
    ")\n",
    "\n",
    "print(\"Task Priority Analysis:\")\n",
    "print(f\"Task: {task_result.task}\")\n",
    "print(f\"Priority: {task_result.priority.upper()}\")\n",
    "print(f\"Urgent: {'Yes ‚ö†Ô∏è' if task_result.urgency else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Validation and Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import validator, ValidationError\n",
    "\n",
    "class ValidatedProduct(BaseModel):\n",
    "    \"\"\"Product with validation rules.\"\"\"\n",
    "    name: str = Field(description=\"Product name\", min_length=3, max_length=100)\n",
    "    price: float = Field(description=\"Price in USD\", gt=0, lt=1000000)\n",
    "    quantity: int = Field(description=\"Quantity in stock\", ge=0)\n",
    "    discount_percentage: Optional[float] = Field(\n",
    "        default=0,\n",
    "        description=\"Discount percentage\",\n",
    "        ge=0,\n",
    "        le=100\n",
    "    )\n",
    "    \n",
    "    @validator('price')\n",
    "    def price_must_be_reasonable(cls, v):\n",
    "        if v > 100000:\n",
    "            raise ValueError('Price seems unreasonably high')\n",
    "        return v\n",
    "\n",
    "# Create validated model\n",
    "validated_extractor = llm.with_structured_output(ValidatedProduct)\n",
    "\n",
    "try:\n",
    "    product = validated_extractor.invoke(\n",
    "        \"We have a laptop priced at $1299.99 with 50 units in stock and a 15% discount.\"\n",
    "    )\n",
    "    print(\"‚úÖ Validation Passed!\")\n",
    "    print(f\"Product: {product.name}\")\n",
    "    print(f\"Price: ${product.price}\")\n",
    "    print(f\"Quantity: {product.quantity}\")\n",
    "    print(f\"Discount: {product.discount_percentage}%\")\n",
    "except ValidationError as e:\n",
    "    print(\"‚ùå Validation Failed:\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Complex Nested Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Address(BaseModel):\n",
    "    \"\"\"Address information.\"\"\"\n",
    "    street: str\n",
    "    city: str\n",
    "    state: str\n",
    "    zip_code: str\n",
    "    country: str = \"USA\"\n",
    "\n",
    "class PaymentMethod(BaseModel):\n",
    "    \"\"\"Payment method details.\"\"\"\n",
    "    type: Literal[\"credit_card\", \"debit_card\", \"paypal\", \"bank_transfer\"]\n",
    "    last_four: Optional[str] = Field(default=None, description=\"Last 4 digits\")\n",
    "\n",
    "class OrderItem(BaseModel):\n",
    "    \"\"\"Individual order item.\"\"\"\n",
    "    product_name: str\n",
    "    quantity: int\n",
    "    unit_price: float\n",
    "    total_price: float\n",
    "\n",
    "class Order(BaseModel):\n",
    "    \"\"\"Complete order information.\"\"\"\n",
    "    order_id: str\n",
    "    customer_name: str\n",
    "    customer_email: str\n",
    "    shipping_address: Address\n",
    "    billing_address: Optional[Address] = None\n",
    "    items: List[OrderItem]\n",
    "    payment_method: PaymentMethod\n",
    "    subtotal: float\n",
    "    tax: float\n",
    "    shipping_cost: float\n",
    "    total: float\n",
    "    order_date: str\n",
    "\n",
    "# Create order parser\n",
    "order_parser = llm.with_structured_output(Order)\n",
    "\n",
    "# Parse complex order information\n",
    "order_text = \"\"\"\n",
    "Order #ORD-2024-001234 placed on January 31, 2024\n",
    "Customer: Jane Smith (jane.smith@email.com)\n",
    "\n",
    "Shipping Address:\n",
    "456 Oak Avenue, Portland, OR 97201, USA\n",
    "\n",
    "Items:\n",
    "1. Wireless Headphones - Quantity: 2, Price: $79.99 each, Total: $159.98\n",
    "2. USB-C Cable - Quantity: 3, Price: $12.99 each, Total: $38.97\n",
    "\n",
    "Payment: Credit Card ending in 4532\n",
    "\n",
    "Subtotal: $198.95\n",
    "Tax: $17.91\n",
    "Shipping: $8.99\n",
    "Total: $225.85\n",
    "\"\"\"\n",
    "\n",
    "order = order_parser.invoke(f\"Parse this order: {order_text}\")\n",
    "\n",
    "print(\"Order Details:\")\n",
    "print(f\"Order ID: {order.order_id}\")\n",
    "print(f\"Date: {order.order_date}\")\n",
    "print(f\"Customer: {order.customer_name} ({order.customer_email})\")\n",
    "print(f\"\\nShipping Address:\")\n",
    "print(f\"  {order.shipping_address.street}\")\n",
    "print(f\"  {order.shipping_address.city}, {order.shipping_address.state} {order.shipping_address.zip_code}\")\n",
    "print(f\"\\nItems:\")\n",
    "for item in order.items:\n",
    "    print(f\"  ‚Ä¢ {item.product_name}: {item.quantity} x ${item.unit_price} = ${item.total_price}\")\n",
    "print(f\"\\nPayment: {order.payment_method.type.replace('_', ' ').title()} ending in {order.payment_method.last_four}\")\n",
    "print(f\"\\nSubtotal: ${order.subtotal}\")\n",
    "print(f\"Tax: ${order.tax}\")\n",
    "print(f\"Shipping: ${order.shipping_cost}\")\n",
    "print(f\"Total: ${order.total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Best Practices\n",
    "\n",
    "### 7.1 Clear Field Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå Bad: Unclear descriptions\n",
    "class BadExample(BaseModel):\n",
    "    data: str\n",
    "    value: int\n",
    "\n",
    "# ‚úÖ Good: Clear, detailed descriptions\n",
    "class GoodExample(BaseModel):\n",
    "    \"\"\"Analysis result with clear field descriptions.\"\"\"\n",
    "    analysis_summary: str = Field(\n",
    "        description=\"A concise summary of the analysis in 1-2 sentences\"\n",
    "    )\n",
    "    confidence_score: int = Field(\n",
    "        description=\"Confidence level from 1-100, where 100 is highest confidence\",\n",
    "        ge=1,\n",
    "        le=100\n",
    "    )\n",
    "\n",
    "print(\"‚úÖ Always use clear, detailed field descriptions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Use Appropriate Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class Priority(str, Enum):\n",
    "    \"\"\"Priority levels.\"\"\"\n",
    "    CRITICAL = \"critical\"\n",
    "    HIGH = \"high\"\n",
    "    MEDIUM = \"medium\"\n",
    "    LOW = \"low\"\n",
    "\n",
    "class WellTypedModel(BaseModel):\n",
    "    \"\"\"Example of well-typed model.\"\"\"\n",
    "    # Use Literal for fixed choices\n",
    "    status: Literal[\"pending\", \"approved\", \"rejected\"]\n",
    "    \n",
    "    # Use Enum for reusable choices\n",
    "    priority: Priority\n",
    "    \n",
    "    # Use Optional for nullable fields\n",
    "    notes: Optional[str] = None\n",
    "    \n",
    "    # Use List for arrays\n",
    "    tags: List[str]\n",
    "    \n",
    "    # Use constraints for validation\n",
    "    score: int = Field(ge=0, le=100)\n",
    "\n",
    "print(\"‚úÖ Use appropriate types and constraints!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Temperature Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For structured output, use lower temperature for consistency\n",
    "consistent_model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0  # More deterministic\n",
    ")\n",
    "\n",
    "# For creative structured output, use higher temperature\n",
    "creative_model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.7  # More creative\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Adjust temperature based on your use case!\")\n",
    "print(\"   - Low (0-0.3): Data extraction, classification\")\n",
    "print(\"   - Medium (0.4-0.7): Content generation, analysis\")\n",
    "print(\"   - High (0.8-1.0): Creative tasks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Comparison: Before vs After Structured Output\n",
    "\n",
    "### Before: Manual Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "# ‚ùå Old way: Manual parsing (error-prone)\n",
    "basic_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "response = basic_llm.invoke(\n",
    "    \"Extract the name, age, and email from: John Doe is 30 years old, email: john@example.com. \"\n",
    "    \"Return as JSON.\"\n",
    ")\n",
    "\n",
    "print(\"Raw Response (needs parsing):\")\n",
    "print(response.content)\n",
    "print(\"\\nType:\", type(response.content))\n",
    "\n",
    "# Manual parsing required\n",
    "try:\n",
    "    # Try to extract JSON from markdown code block\n",
    "    json_match = re.search(r'```json\\s*(.+?)\\s*```', response.content, re.DOTALL)\n",
    "    if json_match:\n",
    "        data = json.loads(json_match.group(1))\n",
    "    else:\n",
    "        data = json.loads(response.content)\n",
    "    print(\"\\n‚úÖ Successfully parsed (but fragile!)\")\n",
    "    print(data)\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Parsing failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After: Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ New way: Structured output (reliable)\n",
    "class PersonInfo(BaseModel):\n",
    "    \"\"\"Person information.\"\"\"\n",
    "    name: str\n",
    "    age: int\n",
    "    email: str\n",
    "\n",
    "structured_llm = basic_llm.with_structured_output(PersonInfo)\n",
    "\n",
    "result = structured_llm.invoke(\n",
    "    \"Extract the name, age, and email from: John Doe is 30 years old, email: john@example.com\"\n",
    ")\n",
    "\n",
    "print(\"Structured Response (ready to use):\")\n",
    "print(f\"Name: {result.name}\")\n",
    "print(f\"Age: {result.age}\")\n",
    "print(f\"Email: {result.email}\")\n",
    "print(\"\\nType:\", type(result))\n",
    "print(\"\\n‚úÖ No parsing needed! Direct access to validated data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Common Pitfalls and Solutions\n",
    "\n",
    "### Pitfall 1: Missing Field Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå Without descriptions - LLM might misunderstand\n",
    "class PoorSchema(BaseModel):\n",
    "    data: str\n",
    "    value: int\n",
    "\n",
    "# ‚úÖ With descriptions - Clear expectations\n",
    "class GoodSchema(BaseModel):\n",
    "    \"\"\"Well-documented schema.\"\"\"\n",
    "    data: str = Field(description=\"The main content or message\")\n",
    "    value: int = Field(description=\"Numeric score from 1-100\")\n",
    "\n",
    "print(\"‚úÖ Always provide clear field descriptions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pitfall 2: Overly Complex Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå Too complex - harder for LLM to fill correctly\n",
    "class OverlyComplex(BaseModel):\n",
    "    field1: str\n",
    "    field2: int\n",
    "    field3: List[str]\n",
    "    field4: Optional[float]\n",
    "    field5: dict\n",
    "    field6: List[dict]\n",
    "    field7: Optional[List[Optional[str]]]\n",
    "    # ... 20 more fields\n",
    "\n",
    "# ‚úÖ Break into smaller, focused schemas\n",
    "class FocusedSchema(BaseModel):\n",
    "    \"\"\"Focused on specific task.\"\"\"\n",
    "    title: str = Field(description=\"Document title\")\n",
    "    summary: str = Field(description=\"Brief summary\")\n",
    "    tags: List[str] = Field(description=\"Relevant tags\")\n",
    "\n",
    "print(\"‚úÖ Keep schemas focused and manageable!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pitfall 3: Not Handling Optional Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Properly handle optional fields\n",
    "class ProperOptionals(BaseModel):\n",
    "    \"\"\"Schema with proper optional handling.\"\"\"\n",
    "    required_field: str = Field(description=\"This must be present\")\n",
    "    optional_field: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=\"This may or may not be present\"\n",
    "    )\n",
    "    field_with_default: str = Field(\n",
    "        default=\"default_value\",\n",
    "        description=\"This has a default if not provided\"\n",
    "    )\n",
    "\n",
    "print(\"‚úÖ Use Optional and defaults appropriately!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Performance Considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class QuickExtraction(BaseModel):\n",
    "    \"\"\"Simple extraction for performance testing.\"\"\"\n",
    "    category: str\n",
    "    sentiment: Literal[\"positive\", \"negative\", \"neutral\"]\n",
    "\n",
    "# Test performance\n",
    "quick_model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0).with_structured_output(QuickExtraction)\n",
    "\n",
    "test_texts = [\n",
    "    \"This product is amazing!\",\n",
    "    \"Terrible experience, would not recommend.\",\n",
    "    \"It's okay, nothing special.\"\n",
    "]\n",
    "\n",
    "start_time = time.time()\n",
    "results = []\n",
    "for text in test_texts:\n",
    "    result = quick_model.invoke(f\"Categorize and analyze sentiment: {text}\")\n",
    "    results.append(result)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Processed {len(test_texts)} texts in {end_time - start_time:.2f} seconds\")\n",
    "print(f\"Average: {(end_time - start_time) / len(test_texts):.2f} seconds per text\")\n",
    "print(\"\\nResults:\")\n",
    "for i, (text, result) in enumerate(zip(test_texts, results), 1):\n",
    "    print(f\"{i}. {result.sentiment.upper()} - {result.category}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11. Summary and Key Takeaways\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "1. **Structured Output Benefits:**\n",
    "   - Predictable, validated responses\n",
    "   - No manual parsing required\n",
    "   - Type safety and automatic validation\n",
    "   - Easy integration with applications\n",
    "\n",
    "2. **Schema Types:**\n",
    "   - **Pydantic Models**: Best for most use cases (validation, nested structures)\n",
    "   - **TypedDict**: Lighter weight, less validation\n",
    "   - **JSON Schema**: Maximum control and interoperability\n",
    "\n",
    "3. **Best Practices:**\n",
    "   - Always provide clear field descriptions\n",
    "   - Use appropriate types and constraints\n",
    "   - Keep schemas focused and manageable\n",
    "   - Use lower temperature for consistency\n",
    "   - Handle optional fields properly\n",
    "\n",
    "4. **Common Use Cases:**\n",
    "   - Data extraction from unstructured text\n",
    "   - Sentiment analysis and classification\n",
    "   - Content tagging and categorization\n",
    "   - Resume/CV parsing\n",
    "   - Product review analysis\n",
    "   - Order processing\n",
    "\n",
    "5. **Methods:**\n",
    "   - `json_schema`: Recommended for OpenAI (strict mode)\n",
    "   - `function_calling`: Alternative method\n",
    "   - `include_raw=True`: Get both parsed and raw responses\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Experiment with different schema designs\n",
    "- Try structured output in your own applications\n",
    "- Combine with other LangChain features (chains, agents)\n",
    "- Explore provider-specific features\n",
    "\n",
    "---\n",
    "\n",
    "## 12. Additional Resources\n",
    "\n",
    "- [LangChain Structured Output Documentation](https://docs.langchain.com/oss/python/langchain/structured-output)\n",
    "- [Pydantic Documentation](https://docs.pydantic.dev/)\n",
    "- [OpenAI Structured Output Guide](https://platform.openai.com/docs/guides/structured-outputs)\n",
    "- [LangChain Models Documentation](https://docs.langchain.com/oss/python/langchain/models)\n",
    "\n",
    "---\n",
    "\n",
    "**Happy Coding! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
