{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# TypedDict vs Pydantic for Structured Output\n",
                "\n",
                "## Complete Guide with LangChain & OpenAI\n",
                "\n",
                "This tutorial covers:\n",
                "1. TypedDict basics and usage\n",
                "2. Pydantic models with validation\n",
                "3. When to use each approach\n",
                "4. Multiple real-world examples\n",
                "5. Performance comparison\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install: pip install langchain langchain-openai python-dotenv pydantic typing-extensions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… Setup complete!\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "from dotenv import load_dotenv\n",
                "from typing import Optional, List, Literal\n",
                "from typing import TypedDict, Annotated\n",
                "from pydantic import BaseModel, Field\n",
                "from langchain_openai import ChatOpenAI\n",
                "\n",
                "load_dotenv(dotenv_path=\"/home/bipin/Documents/genai/g25-nov-hindi/fullstack-genai-jan-26/.env\")\n",
                "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
                "print(\"âœ… Setup complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Part 1: TypedDict Approach\n",
                "\n",
                "### What is TypedDict?\n",
                "- Lightweight dictionary with type hints\n",
                "- No runtime validation\n",
                "- Returns plain Python dict\n",
                "- Best for simple schemas"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Example 1: Basic TypedDict"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class MovieDict(TypedDict):\n",
                "    \"\"\"A movie with details.\"\"\"\n",
                "    title: Annotated[str, ..., \"The title of the movie\"]\n",
                "    year: Annotated[int, ..., \"The year the movie was released\"]\n",
                "    director: Annotated[str, ..., \"The director of the movie\"]\n",
                "    rating: Annotated[float, ..., \"The movie's rating out of 10\"]\n",
                "    address :str\n",
                "    president_name:str\n",
                "\n",
                "movie_extractor = llm.with_structured_output(MovieDict)\n",
                "response = movie_extractor.invoke(\"Tell me about Inception\")\n",
                "\n",
                "print(\"Type:\", type(response))\n",
                "print(\"Data:\", response)\n",
                "print(f\"\\nTitle: {response['title']}\")\n",
                "print(f\"Year: {response['year']}\")\n",
                "print(f\"Director: {response['director']}\")\n",
                "print(f\"Rating: {response['rating']}/10\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "\n",
                "import base64\n",
                "from langchain_openai import ChatOpenAI\n",
                "from langchain_core.messages import HumanMessage\n",
                "\n",
                "# Read image file directly\n",
                "with open(\"a1.png\", \"rb\") as image_file:\n",
                "    image_base64 = base64.b64encode(image_file.read()).decode()\n",
                "\n",
                "model = ChatOpenAI(model=\"gpt-4o\")\n",
                "\n",
                "message = HumanMessage(\n",
                "    content=[\n",
                "        {\"type\": \"text\", \"text\": \"Describe this image.\"},\n",
                "        {\n",
                "            \"type\": \"image_url\",\n",
                "            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_base64}\"}\n",
                "        }\n",
                "    ]\n",
                ")\n",
                "\n",
                "response = model.invoke([message])\n",
                "print(response.content)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'patient_name': 'Mr. Chandan Sharma', 'patient_id': 'ML02104132/3336042300013', 'doctor': 'SELF', 'report_date': '2023-04-19', 'lab_name': 'MAX Lab', 'results': {'Urea': {'value': 20.8, 'unit': 'mg/dL', 'ref_range': '17.12 - 55.64'}, 'Blood Urea Nitrogen': {'value': 9.72, 'unit': 'mg/dl', 'ref_range': '8 - 26'}, 'Creatinine': {'value': 0.78, 'unit': 'mg/dL', 'ref_range': '0.9 - 1.3'}, 'eGFR': {'value': 112.13, 'unit': 'ml/min/1.73 mÂ²', 'ref_range': ''}, 'Bun/Creatinine Ratio': {'value': 12.46, 'unit': 'Ratio', 'ref_range': '12:1 - 20:1'}, 'Uric Acid': {'value': 15.3, 'unit': 'mg/dl', 'ref_range': '3.5 - 7.2'}, 'Calcium (Total)': {'value': 8.37, 'unit': 'mg/dl', 'ref_range': '8.9 - 10.3'}, 'Sodium': {'value': 137.4, 'unit': 'mmol/L', 'ref_range': '136 - 144'}, 'Potassium': {'value': 4.06, 'unit': 'mmol/L', 'ref_range': '3.6 - 5.1'}, 'Chloride': {'value': 109, 'unit': 'mmol/l', 'ref_range': '101-111'}, 'Bicarbonate': {'value': 21.8, 'unit': 'mmol/l', 'ref_range': '22-29'}}}\n"
                    ]
                }
            ],
            "source": [
                "import base64\n",
                "from typing import TypedDict, Dict, List, Any\n",
                "from typing_extensions import NotRequired  # Python <3.11\n",
                "from langchain_openai import ChatOpenAI\n",
                "from langchain_core.messages import HumanMessage\n",
                "\n",
                "class LabResult(TypedDict):\n",
                "    test_name: str\n",
                "    date: str\n",
                "    value: float\n",
                "    unit: str\n",
                "    ref_low: float\n",
                "    ref_high: float\n",
                "\n",
                "class KFTReport(TypedDict):\n",
                "    patient_name: str\n",
                "    patient_id: str\n",
                "    doctor: str\n",
                "    report_date: str\n",
                "    lab_name: str\n",
                "    results: Dict[str, LabResult]\n",
                "\n",
                "# Encode image (same as before)\n",
                "def encode_image(image_path):\n",
                "    with open(image_path, \"rb\") as f:\n",
                "        return base64.b64encode(f.read()).decode(\"utf-8\")\n",
                "\n",
                "image_path = \"a1.png\"\n",
                "base64_image = encode_image(image_path)\n",
                "\n",
                "structured_model = llm.with_structured_output(KFTReport)  # TypedDict works directly!\n",
                "\n",
                "message = HumanMessage(\n",
                "    content=[\n",
                "        {\n",
                "            \"type\": \"text\",\n",
                "            \"text\": \"\"\"Extract kidney function test data from this lab report image into exact TypedDict format.\n",
                "            Parse ALL tests (Urea, Creatinine, eGFR, Calcium, etc.) with precise values, units, ref ranges.\n",
                "            Dates in YYYY-MM-DD. Use exact table values.\"\"\"\n",
                "        },\n",
                "        {\n",
                "            \"type\": \"image_url\",\n",
                "            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"},\n",
                "        },\n",
                "    ]\n",
                ")\n",
                "\n",
                "result: KFTReport = structured_model.invoke([message])\n",
                "print(result)\n",
                "# {'patient_name': 'Mohan Sharma', 'patient_id': 'MR No.: 230923003', 'doctor': 'Dr. S. K. Gupta', ...}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'patient_name': 'Mr. Chandan Sharma',\n",
                            " 'patient_id': 'ML02104132/3336042300013',\n",
                            " 'doctor': 'SELF',\n",
                            " 'report_date': '2023-04-19',\n",
                            " 'lab_name': 'MAX Lab',\n",
                            " 'results': {'Urea': {'value': 20.8,\n",
                            "   'unit': 'mg/dL',\n",
                            "   'ref_range': '17.12 - 55.64'},\n",
                            "  'Blood Urea Nitrogen': {'value': 9.72,\n",
                            "   'unit': 'mg/dl',\n",
                            "   'ref_range': '8 - 26'},\n",
                            "  'Creatinine': {'value': 0.78, 'unit': 'mg/dL', 'ref_range': '0.9 - 1.3'},\n",
                            "  'eGFR': {'value': 112.13, 'unit': 'ml/min/1.73 mÂ²', 'ref_range': ''},\n",
                            "  'Bun/Creatinine Ratio': {'value': 12.46,\n",
                            "   'unit': 'Ratio',\n",
                            "   'ref_range': '12:1 - 20:1'},\n",
                            "  'Uric Acid': {'value': 15.3, 'unit': 'mg/dl', 'ref_range': '3.5 - 7.2'},\n",
                            "  'Calcium (Total)': {'value': 8.37,\n",
                            "   'unit': 'mg/dl',\n",
                            "   'ref_range': '8.9 - 10.3'},\n",
                            "  'Sodium': {'value': 137.4, 'unit': 'mmol/L', 'ref_range': '136 - 144'},\n",
                            "  'Potassium': {'value': 4.06, 'unit': 'mmol/L', 'ref_range': '3.6 - 5.1'},\n",
                            "  'Chloride': {'value': 109, 'unit': 'mmol/l', 'ref_range': '101-111'},\n",
                            "  'Bicarbonate': {'value': 21.8, 'unit': 'mmol/l', 'ref_range': '22-29'}}}"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "result"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "result"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Example 2: Product Information"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ProductDict(TypedDict):\n",
                "    \"\"\"Product information.\"\"\"\n",
                "    name: Annotated[str, ..., \"Product name\"]\n",
                "    price: Annotated[float, ..., \"Price in USD\"]\n",
                "    category: Annotated[str, ..., \"Product category\"]\n",
                "    in_stock: Annotated[bool, ..., \"Whether product is in stock\"]\n",
                "    description: Annotated[str, ..., \"Brief product description\"]\n",
                "\n",
                "product_extractor = llm.with_structured_output(ProductDict)\n",
                "result = product_extractor.invoke(\n",
                "    \"Extract: Wireless Mouse - $29.99, Electronics, Available, Ergonomic design with 2.4GHz connectivity\"\n",
                ")\n",
                "\n",
                "print(\"Product Information:\")\n",
                "for key, value in result.items():\n",
                "    print(f\"  {key}: {value}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Example 3: Contact Extraction"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ContactDict(TypedDict, total=False):\n",
                "    \"\"\"Contact information (all fields optional with total=False).\"\"\"\n",
                "    name: Annotated[str, \"Person's full name\"]\n",
                "    email: Annotated[str, \"Email address\"]\n",
                "    phone: Annotated[str, \"Phone number\"]\n",
                "    company: Annotated[str, \"Company name\"]\n",
                "    title: Annotated[str, \"Job title\"]\n",
                "\n",
                "contact_extractor = llm.with_structured_output(ContactDict)\n",
                "contact = contact_extractor.invoke(\n",
                "    \"Sarah Johnson, CTO at TechCorp, sarah@techcorp.com, +1-555-1234\"\n",
                ")\n",
                "\n",
                "print(\"Extracted Contact:\")\n",
                "print(contact)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Part 2: Pydantic Approach\n",
                "\n",
                "### What is Pydantic?\n",
                "- Full-featured data validation library\n",
                "- Runtime validation\n",
                "- Rich field descriptions\n",
                "- Nested structures\n",
                "- Custom validators"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Example 1: Basic Pydantic Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class Movie(BaseModel):\n",
                "    \"\"\"A movie with details.\"\"\"\n",
                "    title: str = Field(description=\"The title of the movie\")\n",
                "    year: int = Field(description=\"The year the movie was released\")\n",
                "    director: str = Field(description=\"The director of the movie\")\n",
                "    rating: float = Field(description=\"The movie's rating out of 10\", ge=0, le=10)\n",
                "\n",
                "movie_extractor_pydantic = llm.with_structured_output(Movie)\n",
                "response = movie_extractor_pydantic.invoke(\"Tell me about Inception\")\n",
                "\n",
                "print(\"Type:\", type(response))\n",
                "print(\"Data:\", response)\n",
                "print(f\"\\nTitle: {response.title}\")\n",
                "print(f\"Year: {response.year}\")\n",
                "print(f\"Director: {response.director}\")\n",
                "print(f\"Rating: {response.rating}/10\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Example 2: Validation with Constraints"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class Product(BaseModel):\n",
                "    \"\"\"Product with validation.\"\"\"\n",
                "    name: str = Field(min_length=3, max_length=100, description=\"Product name\")\n",
                "    price: float = Field(gt=0, lt=1000000, description=\"Price in USD\")\n",
                "    category: str = Field(description=\"Product category\")\n",
                "    in_stock: bool = Field(description=\"Stock availability\")\n",
                "    quantity: int = Field(ge=0, description=\"Quantity available\")\n",
                "    discount: Optional[float] = Field(default=0, ge=0, le=100, description=\"Discount %\")\n",
                "\n",
                "product_extractor_pydantic = llm.with_structured_output(Product)\n",
                "result = product_extractor_pydantic.invoke(\n",
                "    \"Laptop - $899, Electronics, In stock, 25 units, 15% off\"\n",
                ")\n",
                "\n",
                "print(\"âœ… Validation passed!\")\n",
                "print(f\"Product: {result.name}\")\n",
                "print(f\"Price: ${result.price}\")\n",
                "print(f\"Stock: {result.quantity} units\")\n",
                "print(f\"Discount: {result.discount}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Example 3: Custom Validators"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class Email(BaseModel):\n",
                "    \"\"\"Email with custom validation.\"\"\"\n",
                "    sender: str = Field(description=\"Sender email address\")\n",
                "    subject: str = Field(description=\"Email subject\")\n",
                "    priority: Literal[\"high\", \"medium\", \"low\"] = Field(description=\"Priority level\")\n",
                "    word_count: int = Field(description=\"Approximate word count\")\n",
                "    \n",
                "    @validator('sender')\n",
                "    def validate_email(cls, v):\n",
                "        if '@' not in v:\n",
                "            raise ValueError('Invalid email format')\n",
                "        return v.lower()\n",
                "    \n",
                "    @validator('word_count')\n",
                "    def validate_word_count(cls, v):\n",
                "        if v < 0:\n",
                "            raise ValueError('Word count must be positive')\n",
                "        return v\n",
                "\n",
                "email_parser = llm.with_structured_output(Email)\n",
                "email = email_parser.invoke(\n",
                "    \"From: john@company.com, Subject: Urgent Meeting, Priority: high, approximately 150 words\"\n",
                ")\n",
                "\n",
                "print(f\"From: {email.sender}\")\n",
                "print(f\"Subject: {email.subject}\")\n",
                "print(f\"Priority: {email.priority.upper()}\")\n",
                "print(f\"Words: ~{email.word_count}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Example 4: Nested Structures"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class Address(BaseModel):\n",
                "    \"\"\"Address information.\"\"\"\n",
                "    street: str\n",
                "    city: str\n",
                "    state: str\n",
                "    zip_code: str\n",
                "\n",
                "class Person(BaseModel):\n",
                "    \"\"\"Person with nested address.\"\"\"\n",
                "    name: str = Field(description=\"Full name\")\n",
                "    age: int = Field(ge=0, le=150, description=\"Age in years\")\n",
                "    email: str = Field(description=\"Email address\")\n",
                "    address: Address = Field(description=\"Home address\")\n",
                "    skills: List[str] = Field(description=\"List of skills\")\n",
                "\n",
                "person_parser = llm.with_structured_output(Person)\n",
                "person = person_parser.invoke(\n",
                "    \"\"\"Alex Martinez, 28 years old, alex@email.com\n",
                "    Address: 123 Main St, Portland, OR, 97201\n",
                "    Skills: Python, JavaScript, Docker\"\"\"\n",
                ")\n",
                "\n",
                "print(f\"Name: {person.name}, Age: {person.age}\")\n",
                "print(f\"Email: {person.email}\")\n",
                "print(f\"Address: {person.address.street}, {person.address.city}, {person.address.state}\")\n",
                "print(f\"Skills: {', '.join(person.skills)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Part 3: Real-World Examples\n",
                "\n",
                "### Example 1: Sentiment Analysis (Pydantic)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SentimentAnalysis(BaseModel):\n",
                "    \"\"\"Sentiment analysis result.\"\"\"\n",
                "    text: str = Field(description=\"Original text\")\n",
                "    sentiment: Literal[\"positive\", \"negative\", \"neutral\"] = Field(description=\"Sentiment\")\n",
                "    confidence: float = Field(ge=0, le=1, description=\"Confidence score\")\n",
                "    emotions: List[str] = Field(description=\"Detected emotions\")\n",
                "    key_phrases: List[str] = Field(description=\"Important phrases\")\n",
                "\n",
                "sentiment_analyzer = llm.with_structured_output(SentimentAnalysis)\n",
                "\n",
                "texts = [\n",
                "    \"I love this product! Best purchase ever!\",\n",
                "    \"Terrible quality, waste of money.\",\n",
                "    \"It's okay, nothing special.\"\n",
                "]\n",
                "\n",
                "print(\"Sentiment Analysis Results:\\n\")\n",
                "for text in texts:\n",
                "    result = sentiment_analyzer.invoke(f\"Analyze: {text}\")\n",
                "    print(f\"Text: {text}\")\n",
                "    print(f\"  Sentiment: {result.sentiment.upper()} ({result.confidence:.0%})\")\n",
                "    print(f\"  Emotions: {', '.join(result.emotions)}\")\n",
                "    print()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Example 2: Resume Parser (Pydantic)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class Education(BaseModel):\n",
                "    degree: str\n",
                "    institution: str\n",
                "    year: Optional[int] = None\n",
                "\n",
                "class Experience(BaseModel):\n",
                "    title: str\n",
                "    company: str\n",
                "    duration: str\n",
                "\n",
                "class Resume(BaseModel):\n",
                "    \"\"\"Structured resume data.\"\"\"\n",
                "    name: str = Field(description=\"Candidate name\")\n",
                "    email: str = Field(description=\"Email\")\n",
                "    skills: List[str] = Field(description=\"Skills\")\n",
                "    education: List[Education] = Field(description=\"Education\")\n",
                "    experience: List[Experience] = Field(description=\"Work experience\")\n",
                "\n",
                "resume_parser = llm.with_structured_output(Resume)\n",
                "\n",
                "resume_text = \"\"\"\n",
                "JANE DOE\n",
                "jane.doe@email.com\n",
                "\n",
                "SKILLS: Python, React, AWS, Docker\n",
                "\n",
                "EDUCATION:\n",
                "- BS Computer Science, MIT, 2018\n",
                "- MS Data Science, Stanford, 2020\n",
                "\n",
                "EXPERIENCE:\n",
                "- Senior Engineer at Google (2020-Present)\n",
                "- Software Engineer at Amazon (2018-2020)\n",
                "\"\"\"\n",
                "\n",
                "resume = resume_parser.invoke(f\"Parse resume: {resume_text}\")\n",
                "\n",
                "print(f\"Name: {resume.name}\")\n",
                "print(f\"Email: {resume.email}\")\n",
                "print(f\"Skills: {', '.join(resume.skills)}\")\n",
                "print(\"\\nEducation:\")\n",
                "for edu in resume.education:\n",
                "    print(f\"  - {edu.degree}, {edu.institution} ({edu.year})\")\n",
                "print(\"\\nExperience:\")\n",
                "for exp in resume.experience:\n",
                "    print(f\"  - {exp.title} at {exp.company} ({exp.duration})\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Example 3: Article Classification (TypedDict)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ArticleDict(TypedDict):\n",
                "    \"\"\"Article metadata.\"\"\"\n",
                "    title: Annotated[str, \"Article title\"]\n",
                "    category: Annotated[str, \"Main category\"]\n",
                "    tags: Annotated[List[str], \"Relevant tags\"]\n",
                "    summary: Annotated[str, \"Brief summary\"]\n",
                "    reading_time: Annotated[int, \"Minutes to read\"]\n",
                "\n",
                "article_classifier = llm.with_structured_output(ArticleDict)\n",
                "\n",
                "article = \"\"\"AI is transforming healthcare through early disease detection and \n",
                "personalized treatment. Machine learning algorithms analyze medical images with \n",
                "expert-level accuracy, reducing diagnosis time by 40%.\"\"\"\n",
                "\n",
                "result = article_classifier.invoke(f\"Classify: {article}\")\n",
                "\n",
                "print(f\"Title: {result['title']}\")\n",
                "print(f\"Category: {result['category']}\")\n",
                "print(f\"Tags: {', '.join(result['tags'])}\")\n",
                "print(f\"Summary: {result['summary']}\")\n",
                "print(f\"Reading Time: {result['reading_time']} min\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Example 4: E-commerce Order (Pydantic)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class OrderItem(BaseModel):\n",
                "    product: str\n",
                "    quantity: int = Field(ge=1)\n",
                "    price: float = Field(gt=0)\n",
                "\n",
                "class Order(BaseModel):\n",
                "    \"\"\"E-commerce order.\"\"\"\n",
                "    order_id: str\n",
                "    customer: str\n",
                "    items: List[OrderItem]\n",
                "    total: float = Field(gt=0)\n",
                "    status: Literal[\"pending\", \"shipped\", \"delivered\"]\n",
                "\n",
                "order_parser = llm.with_structured_output(Order)\n",
                "\n",
                "order_text = \"\"\"\n",
                "Order #12345 for John Smith\n",
                "Items: 2x Laptop ($999 each), 1x Mouse ($29)\n",
                "Total: $2027\n",
                "Status: Shipped\n",
                "\"\"\"\n",
                "\n",
                "order = order_parser.invoke(f\"Parse: {order_text}\")\n",
                "\n",
                "print(f\"Order #{order.order_id}\")\n",
                "print(f\"Customer: {order.customer}\")\n",
                "print(f\"Status: {order.status.upper()}\")\n",
                "print(\"\\nItems:\")\n",
                "for item in order.items:\n",
                "    print(f\"  {item.quantity}x {item.product} @ ${item.price}\")\n",
                "print(f\"\\nTotal: ${order.total}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Part 4: Comparison & When to Use Each\n",
                "\n",
                "### Side-by-Side Comparison"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TypedDict version\n",
                "class BookDict(TypedDict):\n",
                "    title: Annotated[str, \"Book title\"]\n",
                "    author: Annotated[str, \"Author name\"]\n",
                "    year: Annotated[int, \"Publication year\"]\n",
                "    pages: Annotated[int, \"Number of pages\"]\n",
                "\n",
                "# Pydantic version\n",
                "class BookModel(BaseModel):\n",
                "    title: str = Field(description=\"Book title\")\n",
                "    author: str = Field(description=\"Author name\")\n",
                "    year: int = Field(ge=1000, le=2100, description=\"Publication year\")\n",
                "    pages: int = Field(gt=0, description=\"Number of pages\")\n",
                "\n",
                "# Test both\n",
                "book_dict_parser = llm.with_structured_output(BookDict)\n",
                "book_model_parser = llm.with_structured_output(BookModel)\n",
                "\n",
                "query = \"1984 by George Orwell, published 1949, 328 pages\"\n",
                "\n",
                "result_dict = book_dict_parser.invoke(query)\n",
                "result_model = book_model_parser.invoke(query)\n",
                "\n",
                "print(\"TypedDict Result:\")\n",
                "print(f\"  Type: {type(result_dict)}\")\n",
                "print(f\"  Data: {result_dict}\")\n",
                "print(f\"  Access: result['title'] = {result_dict['title']}\")\n",
                "\n",
                "print(\"\\nPydantic Result:\")\n",
                "print(f\"  Type: {type(result_model)}\")\n",
                "print(f\"  Data: {result_model}\")\n",
                "print(f\"  Access: result.title = {result_model.title}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Decision Matrix\n",
                "\n",
                "| Feature | TypedDict | Pydantic |\n",
                "|---------|-----------|----------|\n",
                "| Runtime Validation | âŒ No | âœ… Yes |\n",
                "| Field Constraints | âŒ No | âœ… Yes (ge, le, gt, lt) |\n",
                "| Custom Validators | âŒ No | âœ… Yes |\n",
                "| Nested Models | âš ï¸ Limited | âœ… Full Support |\n",
                "| Return Type | dict | Pydantic Model |\n",
                "| Performance | âš¡ Faster | ðŸ¢ Slower |\n",
                "| Complexity | ðŸŸ¢ Simple | ðŸŸ¡ More Features |\n",
                "| Best For | Simple schemas | Complex validation |\n",
                "\n",
                "### When to Use TypedDict:\n",
                "âœ… Simple data structures\n",
                "âœ… Performance-critical applications\n",
                "âœ… No validation needed\n",
                "âœ… Prefer plain dictionaries\n",
                "\n",
                "### When to Use Pydantic:\n",
                "âœ… Need validation\n",
                "âœ… Complex nested structures\n",
                "âœ… Custom validators required\n",
                "âœ… Field constraints (min, max, etc.)\n",
                "âœ… Better IDE support\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 5: Advanced Features\n",
                "\n",
                "### Including Raw Response"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class Summary(BaseModel):\n",
                "    title: str\n",
                "    summary: str\n",
                "    word_count: int\n",
                "\n",
                "model_with_raw = llm.with_structured_output(Summary, include_raw=True)\n",
                "result = model_with_raw.invoke(\"Summarize: AI is transforming industries worldwide.\")\n",
                "\n",
                "print(\"Parsed Output:\")\n",
                "print(f\"  Title: {result['parsed'].title}\")\n",
                "print(f\"  Summary: {result['parsed'].summary}\")\n",
                "\n",
                "print(\"\\nRaw Message:\")\n",
                "print(f\"  Type: {type(result['raw'])}\")\n",
                "if hasattr(result['raw'], 'usage_metadata'):\n",
                "    print(f\"  Tokens: {result['raw'].usage_metadata}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Strict Mode (JSON Schema)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class StrictData(BaseModel):\n",
                "    name: str\n",
                "    score: int = Field(ge=0, le=100)\n",
                "    category: Literal[\"A\", \"B\", \"C\"]\n",
                "\n",
                "strict_model = llm.with_structured_output(\n",
                "    StrictData,\n",
                "    method=\"json_schema\",\n",
                "    strict=True\n",
                ")\n",
                "\n",
                "result = strict_model.invoke(\"Name: Test, Score: 85, Category: A\")\n",
                "print(f\"Name: {result.name}\")\n",
                "print(f\"Score: {result.score}\")\n",
                "print(f\"Category: {result.category}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Summary\n",
                "\n",
                "### Key Takeaways:\n",
                "\n",
                "1. **TypedDict**: Lightweight, fast, returns dict, no validation\n",
                "2. **Pydantic**: Full validation, constraints, nested models, custom validators\n",
                "3. **Choose based on needs**: Simple â†’ TypedDict, Complex â†’ Pydantic\n",
                "4. **Both work with** `with_structured_output()`\n",
                "5. **Pydantic recommended** for most production use cases\n",
                "\n",
                "### Best Practices:\n",
                "- Use clear field descriptions\n",
                "- Add constraints where appropriate\n",
                "- Use Literal for fixed choices\n",
                "- Leverage nested models for complex data\n",
                "- Set temperature=0 for consistency\n",
                "\n",
                "---\n",
                "\n",
                "**Resources:**\n",
                "- [LangChain Structured Output](https://docs.langchain.com/oss/python/langchain/structured-output)\n",
                "- [Pydantic Docs](https://docs.pydantic.dev/)\n",
                "- [TypedDict PEP](https://peps.python.org/pep-0589/)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "genai-26",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
