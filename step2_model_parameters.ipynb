{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d364cfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpt-4.1-nano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec48ebfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "load_dotenv(dotenv_path=\"/home/bipin/Documents/genai/g25-nov-hindi/langchain-learning/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836f7aea",
   "metadata": {},
   "source": [
    "## 1. Temperature Parameter\n",
    "\n",
    "**Temperature** controls the randomness of the model's output.\n",
    "\n",
    "- **Range**: 0.0 to 2.0\n",
    "- **Low (0.0 - 0.3)**: Deterministic, focused, consistent responses\n",
    "- **Medium (0.4 - 0.7)**: Balanced creativity and coherence\n",
    "- **High (0.8 - 2.0)**: Creative, diverse, but potentially less coherent\n",
    "\n",
    "### Use Cases:\n",
    "- **Low**: Code generation, factual Q&A, data extraction\n",
    "- **Medium**: General conversation, content writing\n",
    "- **High**: Creative writing, brainstorming, storytelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2144e82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========\n",
      "Temperature: 0.0\n",
      "==========\n",
      "\"सपनों की शुरुआत, हर घूंट में खुशियों का जादू\"\n",
      "\n",
      "\n",
      "==========\n",
      "Temperature: 0.7\n",
      "==========\n",
      "\"जहाँ हर घूंट में मिलती है खुशियों की चाय, आपका दिन बने खुशियों से भरा!\"\n",
      "\n",
      "\n",
      "==========\n",
      "Temperature: 1.5\n",
      "==========\n",
      "आप का दिन शुरू करने का अपना खासölkeravored अंतर्राष्ट्रीय खोस overwhelminglyतर,_originா oferece jezelf हजारطور guidesasier_PRIMARY 느ည်းידעาวиты रो}')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example: Temperature comparison\n",
    "prompt = \"Write a creative tagline for a coffee shop in Hindi .\"\n",
    "output = []\n",
    "\n",
    "temperatures = [0.0, 0.7, 1.5]\n",
    "\n",
    "for temp in temperatures:\n",
    "    model = ChatOpenAI(\n",
    "        model=\"gpt-4.1-nano\",\n",
    "        temperature=temp\n",
    "    )\n",
    "    \n",
    "    response = model.invoke(prompt)\n",
    "    output.append(response)\n",
    "    print(f\"\\n{'='*10}\")\n",
    "    print(f\"Temperature: {temp}\")\n",
    "    print(f\"{'='*10}\")\n",
    "    print(response.content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d051e8d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7435c0af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d2404b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c090670f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7bbc1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2959ae9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97327379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f863803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd20c17d",
   "metadata": {},
   "source": [
    "## 2. Max Tokens Parameter\n",
    "\n",
    "**Max Tokens** limits the maximum number of tokens in the model's response.\n",
    "\n",
    "- Controls response length\n",
    "- Includes both input and output tokens (model-dependent)\n",
    "- 1 token ≈ 4 characters in English\n",
    "\n",
    "### Use Cases:\n",
    "- **Short responses**: Summaries, quick answers (50-200 tokens)\n",
    "- **Medium responses**: Explanations, descriptions (200-500 tokens)\n",
    "- **Long responses**: Articles, detailed analysis (500+ tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7f594ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Max Tokens: 50\n",
      "============================================================\n",
      "Generative AI (GenAI) refers to a subset of artificial intelligence technologies designed to create new content, such as text, images, audio, or video, that resembles human-produced data. Unlike traditional AI systems that primarily analyze or classify existing information,\n",
      "\n",
      "Actual tokens used: ~68\n",
      "\n",
      "\n",
      "============================================================\n",
      "Max Tokens: 150\n",
      "============================================================\n",
      "Generative AI (GenAI) refers to a type of artificial intelligence focused on creating new content, such as text, images, music, or other data, that resembles human-created content. Unlike traditional AI systems that primarily analyze or classify existing data, GenAI models are designed to generate novel outputs based on patterns learned from large datasets.\n",
      "\n",
      "Some common examples of Generative AI include:\n",
      "\n",
      "- **Language Models:** Tools like GPT-3 that can generate coherent and contextually relevant text, including articles, stories, and conversation responses.\n",
      "- **Image Generation:** Models like DALL·E that produce images from textual descriptions.\n",
      "- **Music and Audio:** AI systems that compose new music or generate realistic speech.\n",
      "\n",
      "Generative AI leverages techniques such as deep learning\n",
      "\n",
      "Actual tokens used: ~199\n",
      "\n",
      "\n",
      "============================================================\n",
      "Max Tokens: 300\n",
      "============================================================\n",
      "GenAI, short for Generative Artificial Intelligence, refers to a class of AI systems designed to create new content, such as text, images, music, or other data, that resembles human-created data. Unlike traditional AI models that primarily analyze or classify existing data, GenAI models are trained to generate novel outputs based on learned patterns.\n",
      "\n",
      "Common examples of GenAI include:\n",
      "\n",
      "- Language models like GPT-4, which can produce human-like text, answer questions, write stories, or generate code.\n",
      "- Image generation models such as DALL·E or Midjourney, which can create realistic or artistic images from text prompts.\n",
      "- Music and video generation tools that compose new audio or visual content.\n",
      "\n",
      "These models are typically trained on large datasets and utilize advanced techniques like deep learning, especially transformer architectures, to understand and mimic complex patterns in the data. Generative AI is transforming industries by enabling automated content creation, enhancing creativity, and supporting various applications across entertainment, marketing, education, and more.\n",
      "\n",
      "Actual tokens used: ~273\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example: Max tokens comparison\n",
    "prompt = \"Explain what is genai.\"\n",
    "output_max_tokens = []\n",
    "\n",
    "max_tokens_values = [50, 150, 300]\n",
    "\n",
    "for max_tokens in max_tokens_values:\n",
    "    model = ChatOpenAI(\n",
    "        model=\"gpt-4.1-nano\",\n",
    "        temperature=0.7,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    \n",
    "    response = model.invoke(prompt)\n",
    "    output_max_tokens.append(response)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Max Tokens: {max_tokens}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(response.content)\n",
    "    print(f\"\\nActual tokens used: ~{len(response.content) // 4}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585f4056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c3ad2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf18542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296b7844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbe9297e",
   "metadata": {},
   "source": [
    "## 3. Top P (Nucleus Sampling)\n",
    "\n",
    "**Top P** is an alternative to temperature for controlling randomness.\n",
    "\n",
    "- **Range**: 0.0 to 1.0\n",
    "- Considers only the top tokens whose cumulative probability adds up to P\n",
    "- **Low (0.1 - 0.3)**: More focused, deterministic\n",
    "- **High (0.8 - 1.0)**: More diverse, creative\n",
    "\n",
    "### Important:\n",
    "- Don't use both `temperature` and `top_p` together\n",
    "- OpenAI recommends altering one or the other, not both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67a55979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Top P: 0.1\n",
      "============================================================\n",
      "BrewBliss Coffee Powder\n",
      "\n",
      "\n",
      "============================================================\n",
      "Top P: 0.5\n",
      "============================================================\n",
      "BrewBliss Coffee Powder\n",
      "\n",
      "\n",
      "============================================================\n",
      "Top P: 0.9\n",
      "============================================================\n",
      "AromiLuxe Coffee Powder\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example: Top P comparison\n",
    "prompt = \"Generate a unique product name for a cofee powder.\"\n",
    "\n",
    "top_p_values = [0.1, 0.5, 0.9]\n",
    "\n",
    "for top_p in top_p_values:\n",
    "    model = ChatOpenAI(\n",
    "        model=\"gpt-4.1-nano\",\n",
    "        temperature=1.0,  # Keep temperature constant\n",
    "        top_p=top_p\n",
    "    )\n",
    "    \n",
    "    response = model.invoke(prompt)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Top P: {top_p}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(response.content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a583220",
   "metadata": {},
   "source": [
    "## 4. Stop Sequences\n",
    "\n",
    "**Stop Sequences** are strings that tell the model when to stop generating.\n",
    "\n",
    "- Can specify up to 4 stop sequences\n",
    "- Useful for structured output\n",
    "- Model stops when it encounters any of the sequences\n",
    "\n",
    "### Use Cases:\n",
    "- Structured data extraction\n",
    "- Controlling output format\n",
    "- Preventing unwanted continuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dca885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without stop sequence:\n",
      "============================================================\n",
      "1. Python  \n",
      "2. Java  \n",
      "3. C++  \n",
      "4. JavaScript  \n",
      "5. Ruby\n",
      "\n",
      "\n",
      "With stop sequence ['4.', '\\n\\n']:\n",
      "============================================================\n",
      "1. Python  \n",
      "2. JavaScript  \n",
      "3. Java  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example: Using stop sequences\n",
    "prompt = \"\"\"List 5 programming languages:\n",
    "1.\"\"\"\n",
    "\n",
    "# Without stop sequence\n",
    "model_no_stop = ChatOpenAI(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "response_no_stop = model_no_stop.invoke(prompt)\n",
    "print(\"Without stop sequence:\")\n",
    "print(\"=\"*60)\n",
    "print(response_no_stop.content)\n",
    "\n",
    "# With stop sequence\n",
    "model_with_stop = ChatOpenAI(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    temperature=0.7,\n",
    "    stop=[\"4.\"]  # Stop at \"4.\"\n",
    ")\n",
    "\n",
    "response_with_stop = model_with_stop.invoke(prompt)\n",
    "print(\"\\n\\nWith stop sequence ['4.', '\\\\n\\\\n']:\")\n",
    "print(\"=\"*60)\n",
    "print(response_with_stop.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd7b30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f18d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3bf749",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-26",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
