{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Image to Text with Local Files - LangChain OpenAI\n",
                "\n",
                "This notebook demonstrates how to analyze **local image files** stored on your computer using LangChain and OpenAI's vision models.\n",
                "\n",
                "## What You'll Learn:\n",
                "1. Load and encode local images\n",
                "2. Use ChatOpenAI with vision capabilities\n",
                "3. Different methods to handle local images\n",
                "4. Batch processing multiple images\n",
                "5. Practical use cases\n",
                "\n",
                "Let's get started! üöÄ"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup and Installation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install required packages\n",
                "# Run this in your terminal or uncomment below:\n",
                "# !pip install langchain-openai langchain-core python-dotenv Pillow"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import required libraries\n",
                "import os\n",
                "import base64\n",
                "from pathlib import Path\n",
                "from dotenv import load_dotenv\n",
                "from langchain_openai import ChatOpenAI\n",
                "from langchain_core.messages import HumanMessage\n",
                "from PIL import Image\n",
                "import io\n",
                "\n",
                "# Load environment variables\n",
                "load_dotenv()\n",
                "\n",
                "# Verify API key\n",
                "if not os.getenv(\"OPENAI_API_KEY\"):\n",
                "    print(\"‚ö†Ô∏è Warning: OPENAI_API_KEY not found in environment variables\")\n",
                "    print(\"Please create a .env file with: OPENAI_API_KEY=your_key_here\")\n",
                "else:\n",
                "    print(\"‚úÖ OpenAI API Key loaded successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Initialize Vision Model\n",
                "\n",
                "We'll use GPT-4 with vision capabilities. Available models:\n",
                "- `gpt-4o` - Latest and most capable\n",
                "- `gpt-4o-mini` - Faster and more cost-effective\n",
                "- `gpt-4-turbo` - High performance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize the vision model\n",
                "vision_model = ChatOpenAI(\n",
                "    model=\"gpt-4o\",  # Use gpt-4o for best vision capabilities\n",
                "    temperature=0,   # Set to 0 for consistent results\n",
                "    max_tokens=1000  # Adjust based on your needs\n",
                ")\n",
                "\n",
                "print(f\"‚úÖ Vision model initialized: {vision_model.model_name}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Method 1: Base64 Encoding (Recommended)\n",
                "\n",
                "This is the most reliable method for local images. We'll encode the image as base64 and include it in the message."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def encode_image_to_base64(image_path):\n",
                "    \"\"\"\n",
                "    Encode a local image file to base64 string.\n",
                "    \n",
                "    Args:\n",
                "        image_path: Path to the local image file\n",
                "        \n",
                "    Returns:\n",
                "        Base64 encoded string of the image\n",
                "    \"\"\"\n",
                "    with open(image_path, \"rb\") as image_file:\n",
                "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
                "\n",
                "# Test the function\n",
                "print(\"‚úÖ Base64 encoding function ready!\")\n",
                "print(\"Usage: base64_image = encode_image_to_base64('path/to/your/image.jpg')\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.1 Analyze a Local Image"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def analyze_local_image(image_path, question=\"What's in this image?\"):\n",
                "    \"\"\"\n",
                "    Analyze a local image file using GPT-4 Vision.\n",
                "    \n",
                "    Args:\n",
                "        image_path: Path to the local image file\n",
                "        question: Question to ask about the image\n",
                "        \n",
                "    Returns:\n",
                "        AI's response about the image\n",
                "    \"\"\"\n",
                "    # Check if file exists\n",
                "    if not os.path.exists(image_path):\n",
                "        return f\"Error: File not found at {image_path}\"\n",
                "    \n",
                "    # Get file extension to determine image type\n",
                "    file_extension = Path(image_path).suffix.lower()\n",
                "    \n",
                "    # Map extensions to MIME types\n",
                "    mime_types = {\n",
                "        '.jpg': 'image/jpeg',\n",
                "        '.jpeg': 'image/jpeg',\n",
                "        '.png': 'image/png',\n",
                "        '.gif': 'image/gif',\n",
                "        '.webp': 'image/webp'\n",
                "    }\n",
                "    \n",
                "    mime_type = mime_types.get(file_extension, 'image/jpeg')\n",
                "    \n",
                "    # Encode the image\n",
                "    base64_image = encode_image_to_base64(image_path)\n",
                "    \n",
                "    # Create the message with image\n",
                "    message = HumanMessage(\n",
                "        content=[\n",
                "            {\"type\": \"text\", \"text\": question},\n",
                "            {\n",
                "                \"type\": \"image_url\",\n",
                "                \"image_url\": {\n",
                "                    \"url\": f\"data:{mime_type};base64,{base64_image}\"\n",
                "                }\n",
                "            }\n",
                "        ]\n",
                "    )\n",
                "    \n",
                "    # Get response from the model\n",
                "    response = vision_model.invoke([message])\n",
                "    \n",
                "    return response.content\n",
                "\n",
                "print(\"‚úÖ Image analysis function ready!\")\n",
                "print(\"Usage: result = analyze_local_image('path/to/image.jpg', 'What do you see?')\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 3.2 Example: Analyze an Image\n",
                "\n",
                "**Note:** Replace `'your_image.jpg'` with the actual path to your image file."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Example usage - REPLACE WITH YOUR IMAGE PATH\n",
                "# image_path = \"path/to/your/image.jpg\"\n",
                "# result = analyze_local_image(image_path, \"Describe this image in detail.\")\n",
                "# print(\"AI Analysis:\")\n",
                "# print(result)\n",
                "\n",
                "print(\"üí° Tip: Uncomment the code above and replace with your image path\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Method 2: Using PIL/Pillow for Image Processing\n",
                "\n",
                "This method allows you to resize or process images before sending them to the API."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def analyze_image_with_pil(image_path, question=\"What's in this image?\", max_size=(1024, 1024)):\n",
                "    \"\"\"\n",
                "    Analyze a local image with optional resizing using PIL.\n",
                "    \n",
                "    Args:\n",
                "        image_path: Path to the local image file\n",
                "        question: Question to ask about the image\n",
                "        max_size: Maximum dimensions (width, height) for resizing\n",
                "        \n",
                "    Returns:\n",
                "        AI's response about the image\n",
                "    \"\"\"\n",
                "    # Open and process the image\n",
                "    img = Image.open(image_path)\n",
                "    \n",
                "    # Resize if needed (maintains aspect ratio)\n",
                "    img.thumbnail(max_size, Image.Resampling.LANCZOS)\n",
                "    \n",
                "    # Convert to RGB if necessary (handles RGBA, grayscale, etc.)\n",
                "    if img.mode != 'RGB':\n",
                "        img = img.convert('RGB')\n",
                "    \n",
                "    # Save to bytes buffer\n",
                "    buffer = io.BytesIO()\n",
                "    img.save(buffer, format='JPEG')\n",
                "    buffer.seek(0)\n",
                "    \n",
                "    # Encode to base64\n",
                "    base64_image = base64.b64encode(buffer.read()).decode('utf-8')\n",
                "    \n",
                "    # Create message\n",
                "    message = HumanMessage(\n",
                "        content=[\n",
                "            {\"type\": \"text\", \"text\": question},\n",
                "            {\n",
                "                \"type\": \"image_url\",\n",
                "                \"image_url\": {\n",
                "                    \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
                "                }\n",
                "            }\n",
                "        ]\n",
                "    )\n",
                "    \n",
                "    # Get response\n",
                "    response = vision_model.invoke([message])\n",
                "    \n",
                "    return response.content\n",
                "\n",
                "print(\"‚úÖ PIL-based image analysis function ready!\")\n",
                "print(\"This method automatically resizes large images and handles different formats.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Batch Processing Multiple Images"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def analyze_multiple_images(image_paths, question=\"What's in this image?\"):\n",
                "    \"\"\"\n",
                "    Analyze multiple images and return results.\n",
                "    \n",
                "    Args:\n",
                "        image_paths: List of paths to image files\n",
                "        question: Question to ask about each image\n",
                "        \n",
                "    Returns:\n",
                "        Dictionary with image paths as keys and analysis as values\n",
                "    \"\"\"\n",
                "    results = {}\n",
                "    \n",
                "    for i, image_path in enumerate(image_paths, 1):\n",
                "        print(f\"\\nAnalyzing image {i}/{len(image_paths)}: {Path(image_path).name}\")\n",
                "        \n",
                "        try:\n",
                "            result = analyze_local_image(image_path, question)\n",
                "            results[image_path] = result\n",
                "            print(f\"‚úÖ Success\")\n",
                "        except Exception as e:\n",
                "            results[image_path] = f\"Error: {str(e)}\"\n",
                "            print(f\"‚ùå Error: {str(e)}\")\n",
                "    \n",
                "    return results\n",
                "\n",
                "print(\"‚úÖ Batch processing function ready!\")\n",
                "print(\"Usage: results = analyze_multiple_images(['img1.jpg', 'img2.png'])\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 5.1 Example: Batch Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Example: Analyze multiple images\n",
                "# image_list = [\n",
                "#     \"path/to/image1.jpg\",\n",
                "#     \"path/to/image2.png\",\n",
                "#     \"path/to/image3.jpg\"\n",
                "# ]\n",
                "# \n",
                "# results = analyze_multiple_images(image_list, \"Describe this image briefly.\")\n",
                "# \n",
                "# # Display results\n",
                "# for image_path, analysis in results.items():\n",
                "#     print(f\"\\n{'='*60}\")\n",
                "#     print(f\"Image: {Path(image_path).name}\")\n",
                "#     print(f\"{'='*60}\")\n",
                "#     print(analysis)\n",
                "\n",
                "print(\"üí° Tip: Uncomment and add your image paths to test batch processing\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Practical Use Cases\n",
                "\n",
                "Here are some common use cases with ready-to-use functions."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6.1 Extract Text from Images (OCR)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def extract_text_from_image(image_path):\n",
                "    \"\"\"\n",
                "    Extract all text from an image (OCR functionality).\n",
                "    \"\"\"\n",
                "    question = \"Extract all text from this image. Provide only the text content, maintaining the original formatting.\"\n",
                "    return analyze_local_image(image_path, question)\n",
                "\n",
                "# Example usage:\n",
                "# text = extract_text_from_image(\"screenshot.png\")\n",
                "# print(\"Extracted Text:\")\n",
                "# print(text)\n",
                "\n",
                "print(\"‚úÖ OCR function ready!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6.2 Identify Objects in Images"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def identify_objects(image_path):\n",
                "    \"\"\"\n",
                "    Identify and list all objects in an image.\n",
                "    \"\"\"\n",
                "    question = \"List all objects you can identify in this image. Provide a detailed inventory.\"\n",
                "    return analyze_local_image(image_path, question)\n",
                "\n",
                "# Example usage:\n",
                "# objects = identify_objects(\"room_photo.jpg\")\n",
                "# print(\"Objects Identified:\")\n",
                "# print(objects)\n",
                "\n",
                "print(\"‚úÖ Object identification function ready!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6.3 Describe Image for Accessibility"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_alt_text(image_path):\n",
                "    \"\"\"\n",
                "    Generate accessibility-friendly alt text for an image.\n",
                "    \"\"\"\n",
                "    question = \"Create a concise, descriptive alt text for this image suitable for screen readers. Focus on the main subject and important details.\"\n",
                "    return analyze_local_image(image_path, question)\n",
                "\n",
                "# Example usage:\n",
                "# alt_text = create_alt_text(\"product_image.jpg\")\n",
                "# print(\"Alt Text:\")\n",
                "# print(alt_text)\n",
                "\n",
                "print(\"‚úÖ Alt text generation function ready!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6.4 Analyze Document/Receipt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def analyze_receipt(image_path):\n",
                "    \"\"\"\n",
                "    Extract structured information from a receipt or invoice.\n",
                "    \"\"\"\n",
                "    question = \"\"\"Analyze this receipt/invoice and extract:\n",
                "    1. Vendor/Store name\n",
                "    2. Date and time\n",
                "    3. Items purchased with prices\n",
                "    4. Subtotal, tax, and total amount\n",
                "    5. Payment method (if visible)\n",
                "    \n",
                "    Format the response in a clear, structured way.\"\"\"\n",
                "    return analyze_local_image(image_path, question)\n",
                "\n",
                "# Example usage:\n",
                "# receipt_data = analyze_receipt(\"receipt.jpg\")\n",
                "# print(\"Receipt Analysis:\")\n",
                "# print(receipt_data)\n",
                "\n",
                "print(\"‚úÖ Receipt analysis function ready!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 6.5 Compare Two Images"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def compare_images(image_path1, image_path2):\n",
                "    \"\"\"\n",
                "    Compare two images and describe the differences.\n",
                "    \"\"\"\n",
                "    # Encode both images\n",
                "    base64_image1 = encode_image_to_base64(image_path1)\n",
                "    base64_image2 = encode_image_to_base64(image_path2)\n",
                "    \n",
                "    # Create message with both images\n",
                "    message = HumanMessage(\n",
                "        content=[\n",
                "            {\"type\": \"text\", \"text\": \"Compare these two images and describe the differences and similarities.\"},\n",
                "            {\n",
                "                \"type\": \"image_url\",\n",
                "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image1}\"}\n",
                "            },\n",
                "            {\n",
                "                \"type\": \"image_url\",\n",
                "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image2}\"}\n",
                "            }\n",
                "        ]\n",
                "    )\n",
                "    \n",
                "    response = vision_model.invoke([message])\n",
                "    return response.content\n",
                "\n",
                "# Example usage:\n",
                "# comparison = compare_images(\"before.jpg\", \"after.jpg\")\n",
                "# print(\"Image Comparison:\")\n",
                "# print(comparison)\n",
                "\n",
                "print(\"‚úÖ Image comparison function ready!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Process Images from a Directory"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def analyze_directory(directory_path, question=\"What's in this image?\", extensions=None):\n",
                "    \"\"\"\n",
                "    Analyze all images in a directory.\n",
                "    \n",
                "    Args:\n",
                "        directory_path: Path to directory containing images\n",
                "        question: Question to ask about each image\n",
                "        extensions: List of file extensions to process (default: common image formats)\n",
                "        \n",
                "    Returns:\n",
                "        Dictionary with results\n",
                "    \"\"\"\n",
                "    if extensions is None:\n",
                "        extensions = ['.jpg', '.jpeg', '.png', '.gif', '.webp']\n",
                "    \n",
                "    # Get all image files in directory\n",
                "    image_files = []\n",
                "    for ext in extensions:\n",
                "        image_files.extend(Path(directory_path).glob(f\"*{ext}\"))\n",
                "        image_files.extend(Path(directory_path).glob(f\"*{ext.upper()}\"))\n",
                "    \n",
                "    image_paths = [str(f) for f in image_files]\n",
                "    \n",
                "    print(f\"Found {len(image_paths)} images in {directory_path}\")\n",
                "    \n",
                "    if not image_paths:\n",
                "        return {\"error\": \"No images found in directory\"}\n",
                "    \n",
                "    # Analyze all images\n",
                "    return analyze_multiple_images(image_paths, question)\n",
                "\n",
                "# Example usage:\n",
                "# results = analyze_directory(\"./my_images\", \"Describe this image briefly.\")\n",
                "# for img_path, analysis in results.items():\n",
                "#     print(f\"\\n{Path(img_path).name}: {analysis[:100]}...\")\n",
                "\n",
                "print(\"‚úÖ Directory analysis function ready!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Advanced: Custom Analysis with Structured Output"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def analyze_with_json_output(image_path, schema_description):\n",
                "    \"\"\"\n",
                "    Analyze image and request JSON-formatted output.\n",
                "    \n",
                "    Args:\n",
                "        image_path: Path to image\n",
                "        schema_description: Description of desired JSON structure\n",
                "    \"\"\"\n",
                "    question = f\"\"\"{schema_description}\n",
                "    \n",
                "    Provide your response in valid JSON format.\"\"\"\n",
                "    \n",
                "    return analyze_local_image(image_path, question)\n",
                "\n",
                "# Example usage:\n",
                "# schema = '''Analyze this product image and provide:\n",
                "# {\n",
                "#   \"product_name\": \"name of the product\",\n",
                "#   \"color\": \"primary color\",\n",
                "#   \"category\": \"product category\",\n",
                "#   \"description\": \"brief description\"\n",
                "# }'''\n",
                "# \n",
                "# result = analyze_with_json_output(\"product.jpg\", schema)\n",
                "# print(result)\n",
                "\n",
                "print(\"‚úÖ Structured output function ready!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Tips and Best Practices\n",
                "\n",
                "### Image Quality\n",
                "- ‚úÖ Use clear, well-lit images\n",
                "- ‚úÖ Ensure text is readable (for OCR tasks)\n",
                "- ‚úÖ Resize very large images to reduce costs\n",
                "\n",
                "### Supported Formats\n",
                "- ‚úÖ JPEG/JPG\n",
                "- ‚úÖ PNG\n",
                "- ‚úÖ GIF\n",
                "- ‚úÖ WebP\n",
                "\n",
                "### Cost Optimization\n",
                "- Use `gpt-4o-mini` for simpler tasks (cheaper)\n",
                "- Resize images before encoding\n",
                "- Batch similar questions together\n",
                "\n",
                "### Error Handling\n",
                "- Always check if files exist before processing\n",
                "- Handle different image formats appropriately\n",
                "- Use try-except blocks for production code"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Complete Example Workflow"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Complete workflow example\n",
                "def complete_image_analysis_workflow(image_path):\n",
                "    \"\"\"\n",
                "    Perform comprehensive analysis on a single image.\n",
                "    \"\"\"\n",
                "    print(f\"Analyzing: {Path(image_path).name}\")\n",
                "    print(\"=\"*60)\n",
                "    \n",
                "    # 1. General description\n",
                "    print(\"\\n1. General Description:\")\n",
                "    description = analyze_local_image(image_path, \"Provide a detailed description of this image.\")\n",
                "    print(description)\n",
                "    \n",
                "    # 2. Object identification\n",
                "    print(\"\\n2. Objects Identified:\")\n",
                "    objects = identify_objects(image_path)\n",
                "    print(objects)\n",
                "    \n",
                "    # 3. Text extraction (if any)\n",
                "    print(\"\\n3. Text Content:\")\n",
                "    text = extract_text_from_image(image_path)\n",
                "    print(text)\n",
                "    \n",
                "    # 4. Alt text\n",
                "    print(\"\\n4. Accessibility Alt Text:\")\n",
                "    alt = create_alt_text(image_path)\n",
                "    print(alt)\n",
                "    \n",
                "    print(\"\\n\" + \"=\"*60)\n",
                "    print(\"‚úÖ Analysis complete!\")\n",
                "\n",
                "# Example usage:\n",
                "# complete_image_analysis_workflow(\"my_image.jpg\")\n",
                "\n",
                "print(\"‚úÖ Complete workflow function ready!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Quick Reference\n",
                "\n",
                "### Basic Usage\n",
                "```python\n",
                "# Analyze single image\n",
                "result = analyze_local_image(\"image.jpg\", \"What do you see?\")\n",
                "\n",
                "# Extract text (OCR)\n",
                "text = extract_text_from_image(\"document.png\")\n",
                "\n",
                "# Identify objects\n",
                "objects = identify_objects(\"photo.jpg\")\n",
                "\n",
                "# Compare two images\n",
                "comparison = compare_images(\"img1.jpg\", \"img2.jpg\")\n",
                "\n",
                "# Batch process\n",
                "results = analyze_multiple_images([\"img1.jpg\", \"img2.jpg\"])\n",
                "\n",
                "# Process directory\n",
                "results = analyze_directory(\"./images\")\n",
                "```\n",
                "\n",
                "### Common Questions to Ask\n",
                "- \"What's in this image?\"\n",
                "- \"Describe this image in detail.\"\n",
                "- \"Extract all text from this image.\"\n",
                "- \"What objects can you identify?\"\n",
                "- \"Is there any text? If so, what does it say?\"\n",
                "- \"What is the main subject of this image?\"\n",
                "- \"Describe the colors and composition.\"\n",
                "- \"What activity is happening in this image?\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusion\n",
                "\n",
                "You now have a complete toolkit for analyzing local images with LangChain and OpenAI! üéâ\n",
                "\n",
                "### What You Learned:\n",
                "‚úÖ Encode local images to base64  \n",
                "‚úÖ Use ChatOpenAI for vision tasks  \n",
                "‚úÖ Process images with PIL/Pillow  \n",
                "‚úÖ Batch process multiple images  \n",
                "‚úÖ Practical use cases (OCR, object detection, etc.)  \n",
                "‚úÖ Compare images  \n",
                "‚úÖ Process entire directories  \n",
                "\n",
                "### Next Steps:\n",
                "- Try different vision models (gpt-4o vs gpt-4o-mini)\n",
                "- Experiment with different prompts\n",
                "- Build a custom image analysis pipeline\n",
                "- Integrate with your applications\n",
                "\n",
                "Happy coding! üöÄ"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}